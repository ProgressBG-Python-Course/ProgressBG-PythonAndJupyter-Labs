{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       _index _type        _id  _score              comp       dcid  \\\n",
      "0  mdw_v0.0.7   doc  663330971       4             ZF_EN  663330971   \n",
      "1  mdw_v0.0.7   doc  663348073       4          VASCNEWS  663348073   \n",
      "2  mdw_v0.0.7   doc  663348044       4         VASCBNEWS  663348044   \n",
      "3  mdw_v0.0.7   doc  663348214       4        CIA_CZAMEN  663348214   \n",
      "4  mdw_v0.0.7   doc  663348449       4          PL-PAPMI  663348449   \n",
      "5  mdw_v0.0.7   doc  663352796       4            MTIECO  663352796   \n",
      "6  mdw_v0.0.7   doc  663330592       4     BUSINESS_LINE  663330592   \n",
      "7  mdw_v0.0.7   doc  663347198       4  NM_TR_ALBWBA_QAT  663347198   \n",
      "8  mdw_v0.0.7   doc  663346485       4     QA-RAYA-GULFT  663346485   \n",
      "9  mdw_v0.0.7   doc  663346506       4     QA-RAYA-GULFT  663346506   \n",
      "\n",
      "   scope/code  scope/probability  industry/code  industry/probability  \\\n",
      "0          25              99.60            531                 99.97   \n",
      "1          25             100.00            531                 99.95   \n",
      "2          25             100.00            531                 99.90   \n",
      "3          25              99.98            531                 99.91   \n",
      "4          25             100.00            531                 99.66   \n",
      "5          25              98.37            531                 99.97   \n",
      "6          25              98.03            531                 99.98   \n",
      "7          25              99.92            531                 99.86   \n",
      "8          25              98.66            531                 99.87   \n",
      "9          25             100.00            531                 99.49   \n",
      "\n",
      "                                                titl  \n",
      "0  Vastint To Start Construction Of Second Phase ...  \n",
      "1    Da Nang orders dismantling of luxury apartments  \n",
      "2  Real estate loans make up 1/5 of total outstan...  \n",
      "3    C&W advised Cromwell on Galerie Butovice's sale  \n",
      "4  StockWatch: PZU insurance on mgmt; PKP Cargo o...  \n",
      "5    Survey augurs stagnating home prices in capital  \n",
      "6  String Real Estate to hike India headcount to ...  \n",
      "7     UDC's nine-month net profit hits QR343 million  \n",
      "8  UDC registers net profit of QR343mn over QR1.3...  \n",
      "9  Qatari Diar unveils Downtown Lusail brand at C...  \n"
     ]
    }
   ],
   "source": [
    "# preprocess data with Python before loading it into df\n",
    "f = open('../datasets/ES.json')\n",
    "raw_data = json.loads(str(f.read()))\n",
    "\n",
    "# create a new list of dicts, which will hold the values we need\n",
    "processed = []\n",
    "\n",
    "# the data we actually need\n",
    "hits_dict = raw_data['hits']['hits']\n",
    "    \n",
    "# TODO: explain with recursive function, if have time\n",
    "def process_dict_items(d):\n",
    "    # create a new dict to store row data\n",
    "    row_dict = {}\n",
    "    \n",
    "    # now iterate over dict items:\n",
    "    for k, v in d.items():\n",
    "        if k == '_source':\n",
    "            tags = v['tags']\n",
    "            for k, v in tags.items():\n",
    "                try: # if value is compound                                                           \n",
    "                    for comp_k, comp_v in v[0].items():\n",
    "                        row_dict[f'{k}/{comp_k}'] = comp_v                                            \n",
    "                except:\n",
    "                    row_dict[k] = v   \n",
    "        else:\n",
    "            row_dict[k] = v\n",
    "            \n",
    "    return row_dict\n",
    "    \n",
    "\n",
    "# so we have a list of dictionaries - let's iterate over it:\n",
    "for d in hits_dict:\n",
    "    row_dict = process_dict_items(d)\n",
    "    processed.append(row_dict)\n",
    "    \n",
    "    \n",
    "# create a DataFrame\n",
    "df = pd.read_json(json.dumps(processed)) \n",
    "print(df.head(10))\n",
    "\n",
    "\n",
    "# write to excell:\n",
    "output_file_name = '../.tmp/es.xlsx' \n",
    "df.to_excel(output_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
